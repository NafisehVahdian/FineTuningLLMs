{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"transformers>=4.40.0\" \"datasets\" \"peft\" \"accelerate\" \"bitsandbytes\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmFbwKrY38QF",
        "outputId": "c6fcc222-3b21-4e81-c5ae-d768f9815317"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "cNv67qXQ6IHg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"math_tutor_train_v2.jsonl\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "\n",
        "print(train_dataset[0])\n",
        "print(\"Number of examples:\", len(train_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "175eef885e1e46faa6f5c5b769cea268",
            "628b1b459984499c9e7647c2fb2d67b2",
            "0af99313602a44b281888c0995f72ce2",
            "c6bb3a8bbc994050b256a237d4fa2f83",
            "afcabc9741b040a89e10f1696d6a9f34",
            "b5655a9780a146f7aaddcf2c06e133c8",
            "b6da6ea2deee4b88a7cbeff0d8150660",
            "1913ecbe47304036bb66bd7127f21f70",
            "0b12be641e31463abc1aab59ded24065",
            "dff7b9990e534787abfffc1a47f9c5ad",
            "6a4b3e639b9241dc991c5ea3c0ddf6ac"
          ]
        },
        "id": "51NUdUuO4QCN",
        "outputId": "de735559-16d0-431c-990d-4dafb82f2448"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "175eef885e1e46faa6f5c5b769cea268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'What is 12 + 15?', 'input': '', 'output': '12 + 15 = 27. I add 10 to 12 to get 22, then add the remaining 5 to reach 27.'}\n",
            "Number of examples: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,   # load model in 4-bit (saves GPU memory)\n",
        "    device_map=\"auto\"    # automatically use GPU\n",
        ")\n",
        "\n",
        "print(\"Model + tokenizer loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "562995a73c34499cbb7fd6af53f80783",
            "82fbea5f7ee847a4a1836cf85ba87542",
            "b527a7ac8dc74c3fa42823fa21ae8270",
            "de1ab74219d345d4b47112aee3d20e5f",
            "c5d6f6d221c545a69e2d92196ce44927",
            "4709330c5dcd46baa26b293dbcb1e459",
            "1a64a6bc301a451f9effd44d3c7e1ff9",
            "89fd4bd70dfc4f1c82aa55d84e33dfaf",
            "ce07103f64e74788b48ce6529747d27b",
            "2f42a163ee65436c81caeefdf2b78351",
            "29a2deecdda44e0ba8774f6a5afc9f16",
            "3e70e381457f4d42b7773484e6c3c2ee",
            "985ae4bbb8dc4d2ebf4b2b852c560b57",
            "8cee1a29d3b44d57a3c712876ba09459",
            "64870fc74491479ca094b64cf4df3fd7",
            "21d0a3c563ef44619abd3dcd45580267",
            "726ef1c5d0df41cda32ef9923d310d38",
            "fccb464b5c394e999bc5478a123ae072",
            "b6c7a0a1e4b94211b151a008bd8dc774",
            "c259ff9cc4f840dda88fd5f67c0d38ea",
            "5fc7890fec404c4896ca74de23c30aed",
            "a08f7a05b5bf4363901f2c4bfb0113c8",
            "57f0c061a07248068549fdbcb4fea6ab",
            "b20c91f2d7154cd8b077a94ed109fffa",
            "29efb75080874b95ac0d054cba508733",
            "bc800f6f0cf14556ac57223b3d9e6b27",
            "10b9252c7eb0485989c82c246b3fb156",
            "9c3c93106eea4ad29c425482b8c724a1",
            "2e6181d25be14c0d99d09dc1cb8f50d0",
            "1340d649e04e4ed6a04ef3de72cc9915",
            "8c89814e49ef40efa98b59046f0d637b",
            "58cf7d383be543bfb29ce1d4500f69a9",
            "83efd9e2b938462799dd09f096ad3bb4",
            "3998a74c407a428c9269587b958c7d15",
            "455cb308cdc140728c4e0c782f780686",
            "045a445be89f4634bb0c829ff560f7bd",
            "7cc6e56ceda8454aaa0ce41e2ae9b753",
            "79761689be7b4cb3a21249f25c1c654d",
            "d03619209cc1407abcb9fcc6bf034c0a",
            "9f87db771e274c4888eb83d70cb628ff",
            "46b10f8c5b294a9aa87e4ebd5ae11929",
            "642050050139486d822c50b355f2747a",
            "098f38f5a3894b2a9c1b8b760691c072",
            "3559fe03a0844a978635810a33f31d3d",
            "7a1e3a0c89744b5aa47f8ae4657c49d0",
            "e57f97adbae945a8b33e6ab677ff3382",
            "a549cf80f14949d49bbb8a36c2206f9f",
            "d17bf0dd846b4514845954db69693a93",
            "f2c06aaaa5c441219ff88f69ccf38742",
            "015ba400a3ea4785a1c838224221c924",
            "596c3e4fb3f14b479fa072af614e2b50",
            "5a05f049c1c34b938213dc546d293536",
            "65f492710da64434b477e89b28608078",
            "515180d19e474c738be4ee66cc2b75c5",
            "09d2cbd317724775b418c80b41412cf7",
            "7a1b457dbc3d403a8824e68f62be1480",
            "f1a6b59dd6094fbe896636995c38ed1e",
            "4a2ed72412f64bed826ead90cf875de3",
            "769f8f88e7f24e24876883be80739d1f",
            "b5e60a0ecd194e0c97d4aa1bf825024f",
            "480c82eaa0a7423b93795c3083148c04",
            "515d414d5f0047a6bdc75162934fefaa",
            "bd003efba93b40278646a0b98b070a59",
            "a6fa834f369f4c2f86aa2090c88751a2",
            "ee7791145e49455588d35f594e3cd061",
            "b4f49ec74940441793e53625d32334fa",
            "36bf7fb1c4294792a76d2b3c27b41538",
            "3f88e538b1334a47a5a6b893fb9edd96",
            "03335f6198ea4573bac9870bd4f3d21a",
            "c599d828aa104df3a5ec1cb02a71d1f9",
            "1e67f2a77d0f462ab44665e2aa1a031d",
            "2960f51aecf04fbe896712d3a0fcb08f",
            "d1b1e672d6694ed6877909825e95a277",
            "64d414a26c584348870f0d933f761f6d",
            "e9c029eda60a4da6bb68afa53a93d898",
            "d77236f094ef4008b38d8e111eeb91a6",
            "b0dc5e57bbd144dd8e1d23e0bca50358"
          ]
        },
        "id": "r8uZ0K6t4ehh",
        "outputId": "2405e1c0-b2f9-4d44-c926-c7af1bfb64b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "562995a73c34499cbb7fd6af53f80783"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e70e381457f4d42b7773484e6c3c2ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f0c061a07248068549fdbcb4fea6ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3998a74c407a428c9269587b958c7d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a1e3a0c89744b5aa47f8ae4657c49d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a1b457dbc3d403a8824e68f62be1480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36bf7fb1c4294792a76d2b3c27b41538"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model + tokenizer loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,                   # rank of LoRA matrices (small = fast & light)\n",
        "    lora_alpha=16,         # scaling factor\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\", # we are training a causal language model\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bMx90bQ470l",
        "outputId": "2e6ee802-8b86-4c48-fd4c-c5adf2885f16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    instruction = example[\"instruction\"]\n",
        "    output = example[\"output\"]\n",
        "\n",
        "    # Build a simple prompt format\n",
        "    text = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}\"\n",
        "\n",
        "    # Turn text into token IDs\n",
        "    tokenized = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # For causal language modelling, labels = input_ids\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "tokenized_train = train_dataset.map(format_example)\n",
        "\n",
        "print(tokenized_train[0].keys())\n",
        "print(\"Tokenized training examples:\", len(tokenized_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "c147ba59c1a5465e92d453070b2a5376",
            "93a89e90c15745efbd9dcaf8249967ce",
            "1d020124f8c64497b46e6b5109640079",
            "b168cded9601456d8d3fdfc96a94164b",
            "5f3b4a86ed3c4e09880716d0ae5b7dcf",
            "06d030fe3c424cd79e72e235ae0c21e5",
            "cfb658c700464488a2fabb8673b3055c",
            "c175ad7d132d445c9b6756a3683fc392",
            "434ae4a254274879bee16bc5be2a9b7b",
            "2c16025e89c8405abb0f5e655239ba33",
            "f92424be366f4c54ab44947f0c50b132"
          ]
        },
        "id": "1eZxa_jS5IBM",
        "outputId": "1a3ab8e1-1284-4cb4-82cb-a6860f68ee6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c147ba59c1a5465e92d453070b2a5376"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['instruction', 'input', 'output', 'input_ids', 'attention_mask', 'labels'])\n",
            "Tokenized training examples: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./math-tutor-lora\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=1,\n",
        "    save_steps=50,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False   # mlm = masked language modeling (not used for chat models)\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ApGW_7U25VtN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "VvgmQk_J5hIc",
        "outputId": "4b1593d1-5a91-4b91-866f-9df9a7798faa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.859000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.969600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.858800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.714700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.488200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.380500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.257500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.507300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.206400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.179800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.177500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.192300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.050100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.149300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.153100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.880800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.786200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.770700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.157400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=27, training_loss=1.2479946569160179, metrics={'train_runtime': 22.0638, 'train_samples_per_second': 4.487, 'train_steps_per_second': 1.224, 'total_flos': 157654660939776.0, 'train_loss': 1.2479946569160179, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./math-tutor-lora\")\n",
        "tokenizer.save_pretrained(\"./math-tutor-lora\")\n",
        "\n",
        "print(\"Fine-tuned LoRA adapter and tokenizer saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nwFHamf60Ty",
        "outputId": "1928c3a1-6539-4fe8-b9f2-d44d215b1c33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned LoRA adapter and tokenizer saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# Reload the base model in 4-bit\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Load your fine-tuned LoRA adapter\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"./math-tutor-lora\")\n",
        "\n",
        "ft_model.eval()\n",
        "\n",
        "# Build a text-generation pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=ft_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=150,\n",
        "    do_sample=True,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "def ask(question):\n",
        "    prompt = f\"### Instruction:\\n{question}\\n\\n### Response:\\n\"\n",
        "    answer = pipe(prompt)[0][\"generated_text\"]\n",
        "    print(answer)\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "ask(\"What is 27 + 14?\")\n",
        "ask(\"Explain what speed means.\")\n",
        "ask(\"Which number is larger, 0.4 or 0.09?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE5l1YBk68Mn",
        "outputId": "fca35560-e0e1-4d46-a700-409f453e1035"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "What is 27 + 14?\n",
            "\n",
            "### Response:\n",
            "27 + 14 = 41. So 41 - 14 = 27.\n",
            "\n",
            "============================================================\n",
            "\n",
            "### Instruction:\n",
            "Explain what speed means.\n",
            "\n",
            "### Response:\n",
            "Speed is the amount of change in a distance per time period. For example, if you run at a speed of 5 miles per hour for 2 minutes, that means you have covered 5 miles in 2 minutes.\n",
            "\n",
            "============================================================\n",
            "\n",
            "### Instruction:\n",
            "Which number is larger, 0.4 or 0.09?\n",
            "\n",
            "### Response:\n",
            "0.4 > 0.09 = 0.4 > 0.09 = 0.4 > 0.09 = 0.4 = 0.4.\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}